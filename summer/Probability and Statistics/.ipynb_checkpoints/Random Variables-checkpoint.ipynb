{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d084fd61",
   "metadata": {},
   "source": [
    "## Probability  and Inferential Statistics\n",
    "----\n",
    "Module 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e61ee9",
   "metadata": {},
   "source": [
    "### Probability:    \n",
    "\n",
    "Probability is the branch of mathematics concerning *Numerical Descriptions* of how **likely** an *Event* of an experiment is to occur. The probability of an event is a number between 0 and 1, where- 0 indicates impossibility of the event and 1 indicates certainty.  \n",
    "  \n",
    "$S$(Sample space) - set of all the possible events in an experiment($E$).    \n",
    "$P(x)$ - Probabilty of occuring $x; \\hspace{2mm} x \\in S$ (x is an event of experiment $E$)\n",
    "\n",
    "* $0 \\leq P(x) \\leq1~$ \n",
    "* $\\sum_S P(x) = 1~$ : sum of Probabilities of all the events in $S$ is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ea5443",
   "metadata": {},
   "source": [
    "### Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e9146d",
   "metadata": {},
   "source": [
    "Literally it means, a VARIABLE whose possible Values are outcomes of an 'random process', in Numerical Terms.  \n",
    "Mathematical defination:  \n",
    "*Real Valued function that maps possible outcomes(S) of an experiment(E) to a real number(R).*  \n",
    "$X: S \\rightarrow \\mathbb{R} $  [ X: Random Variable, S->Sample space, R->Real No.s set ]\n",
    "\n",
    "Lets, define a Random Variable of tossing a coin experiment:   \n",
    "$X = \\begin{cases}\n",
    "1 & ,head\\\\\n",
    "0 & ,tail\\end{cases}$  \n",
    "\n",
    "For $X(S)$:\n",
    "* Domain - { head, tail}\n",
    "* Range  - {1, 0}\n",
    "\n",
    "Machine learning is all about predicting outcomes in our daily life. These outcomes/events cannot be understood by computer as we understand them. These events are needed to translated to machine's language, which is nothing but numbers(binary). Random Variable is the mathematical tool, need to be defined by humans, which will act as that translator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d54a1",
   "metadata": {},
   "source": [
    "### Types of Random Variables  \n",
    "* Discrete R.V. :  \n",
    "    Range of X(S) is **finite or countable**  \n",
    "    Ex - tossing coin, lottery ticket   \n",
    "    We get dicrete probability distribution for X\n",
    "\n",
    "  \n",
    "* Continuous R.V. :  \n",
    "    Range of X(S) is **an interval / uncountable**  \n",
    "    Ex - water levels of dam   \n",
    "    We get continuous probability distribution for X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faed55f",
   "metadata": {},
   "source": [
    "### Probability mass/density Function (PDF):\n",
    "\n",
    "The main purpose of creating random variable, is to make it easier for us to plot probability distribution function. Then let us define probability function with the help of R.V.   \n",
    "$f(x) = P(X=x)\\hspace{1.5cm}$  [f:pdf, P:probality, X:R.V, x: real no.]   \n",
    "    Probability Density Function $f(x)$ is equals to the **Probability** of the **event** $X=x~$(denotes the event mapped to a Real no. $x$).  \n",
    "    \n",
    "* $0 \\leq f(x) \\leq1~$ \n",
    "* $\\sum f(x) = 1~$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacbf3b1",
   "metadata": {},
   "source": [
    "### Cummulative distribution Function (CDF)   \n",
    "$F(a) = P(X<=a)\\hspace{1.5cm}$[F:cdf, P:probality, X:R.V, a: real no.]  \n",
    "Cummulative distribution Function F(a) is the probability that r.v X will take a value less than or equal to a(which are all events who is mapped to a value less than equal to a).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea92a1c",
   "metadata": {},
   "source": [
    "**Relation between PDF and CDF**  \n",
    "* For Discrete: $\\hspace{1mm}x \\hspace{1mm}assumes\\hspace{1mm} [ x_1, x_2, x_3...]$    \n",
    "    \n",
    "    * $F(a) = \\sum_{x=-\\infty}^{a} ~ f(x)$  \n",
    "  \n",
    "    * $f(x_a) = F(x_a)-F(x_{a-1})$  \n",
    "    \n",
    "        \n",
    "* For Continuous:    \n",
    " \n",
    "    * $F(a) = \\int_{-\\infty}^{a} f(x) \\,dx $  \n",
    "     \n",
    "    * $f(x) = \\frac{d}{dx} F(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb03cc1",
   "metadata": {},
   "source": [
    "### 2 dimensional random variables [Bivariate]:    \n",
    "\n",
    "Let $S$ be a sample space(outcomes) associated with a random experiment($E$). Let $X$ and $Y$ be two random variables defined on $S$. then the pair $(X,Y)$ is called a Two – dimensional random variable.\n",
    "The value of ($X,Y$) at a point $s$ in $S$ is given by the   \n",
    "ordered pair of real numbers $(\\hspace{1mm}X(s), Y(s)\\hspace{1mm}) = (x, y)$, where $X(s) = x, Y(s) = y$.  \n",
    "\n",
    "We can also say Bivariate is a real valued function which maps pair of outcomes of an experiment to a pair of real no.s.  \n",
    "therefore; function $X_b: S\\times S \\rightarrow \\mathbb{R} \\times \\mathbb{R} \\hspace{5mm}$ [X<sub>b</sub>-bivariate; S-outcomes; R-real no.s]\n",
    "\n",
    "Lets, define a 2dims Random Variable of tossing a pair of coin experiment:\n",
    "$(X,Y) = \\begin{cases}\n",
    "11 & ,HH\\\\\n",
    "10 & ,HT\\\\\n",
    "01 & ,TH\\\\\n",
    "11 & ,TT\\end{cases}$    \n",
    "* Domain of (X,Y) = {HH, HT, TH, TT}\n",
    "* Range of (X,Y) = {(1,1),(1,0),(0,1),(0,0)}  \n",
    "  \n",
    "It is evident, from the above example, that X and Y random variables are defined on 2 separate coins similarly. Combining the 2 similar experiments, gave rise to a whole new experiment, requiring higher dimensional random variables to translate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430f9f25",
   "metadata": {},
   "source": [
    "* Joint Probability function:  \n",
    "    $f(x,y) = P\\{X=x ~and~ Y=y\\};  \\hspace{1cm} [ ~(i)f(x,y) >=0, ~~(ii)\\sum_{x}\\sum_{y} f(x,y) = 1  ]$  \n",
    "      \n",
    "* Joint Cummulative Distribution function:  \n",
    "    $F_{(X,Y)}(x,y) = P\\{ X<=x, Y<=y\\}; \\hspace{1cm} ( -\\infty<x,y<\\infty$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca81dd",
   "metadata": {},
   "source": [
    "#### Relation between them:  \n",
    "* for Discrete ~  \n",
    "​\n",
    "    * $F_{(X,Y)}(x,y) = \\sum_{x_i}\\sum_{y_j} f(x_i, y_j);~~$ [ where x<sub>i</sub>, y<sub>j</sub> takes discrete variables]  \n",
    "         $\\hspace{1mm}$ \n",
    "    * $f(x_i, y_j) = F_{(X,Y)}(x_i,y_j)- F_{(X,Y)}(x_{i-1},y_{j-1})~~$ [i=1,2,3.., j=1,2,3..]\n",
    "    \n",
    "           \n",
    "* for continuous ~    \n",
    "    * $F_{(X,Y)}(x,y) = \\int_{-\\infty}^{x} \\int_{-\\infty}^{y} f(x,y) \\,dxdy$   \n",
    "        $\\hspace{1mm}$ \n",
    "    * $f(x, y) = \\frac{\\partial^2 F(x,y)}{\\partial x \\partial y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e394e25",
   "metadata": {},
   "source": [
    "### Marginal Probability density Function:  \n",
    "\n",
    "  The fuction which yields probability of one event in the presence of all outcomes of the other random variable is called the marginal probability function of that event.  \n",
    "So, Marginal Probability function of X in the presence of Y is -\n",
    "   * Discrete -  \n",
    "    $f_X(x) = \\sum_j f(x, y_j);~~$ [j=1,2,3...]  \n",
    "​\n",
    "   * Continuous -  \n",
    "    $f_X(x) = \\int_{-\\infty}^{\\infty} f(x, y) dy;~~$ [summing over Y]   \n",
    " \n",
    " where,  \n",
    " * $0 \\leq f_X(x),f_Y(y) \\leq 1$\n",
    " * $\\sum f_X(x) =1 = \\sum f_Y(y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff7d10",
   "metadata": {},
   "source": [
    "### Marginal Distribution Function:  \n",
    "\n",
    "$F_X(x) = P\\{X<=x, -\\infty <Y<\\infty \\};\\\\\n",
    "\\hspace{1.3cm}= \\lim_{y \\to \\infty}F_{X,Y}(x,y)$   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f52f31",
   "metadata": {},
   "source": [
    "### Conditional Probability  \n",
    "Conditional probability is defined as the likelihood of an event or outcome occurring, based on the occurrence of a previous event or outcome.  \n",
    "Therefore, probability of event A given that event B has occured:  \n",
    "$P(A|B) = \\frac{P(AB)}{P(B)}, \\hspace{2mm}if\\hspace{2mm} P(B)\\neq0\\hspace{1cm}$[where P(AB) is probability of occuring both the events A,B]   \n",
    "  \n",
    "in terms of random variable:  \n",
    "$P(X=x|Y=y)\\hspace{2mm}=\\hspace{2mm}\\frac{P(X=x,Y=y)}{P(Y=y)}$  \n",
    "  or  \n",
    "$f(x|y)=\\frac{f(x,y)}{f_Y(y)}\\hspace{1cm}$[where f(x,y) is joint density function of X,Y and f<sub>Y</sub>(y) is marginal density function of Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf71072",
   "metadata": {},
   "source": [
    "### Independence of Random Variable  \n",
    "An independent random variable is a random variable that doesn't have an effect on the other random variables in your experiment.  \n",
    "Condition:  \n",
    "$P(AB) = P(A) \\times P(B)$  \n",
    "  or  \n",
    "$f_{XY}(x,y) = f_X(x) \\times f_Y(y)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194f29c0",
   "metadata": {},
   "source": [
    "### Expectation  \n",
    "The expected value of a Random Variable is the Weighted Average of all possible values of the variable.  \n",
    "Expectation is nothing but **Mean** - measure of the center of the **probability distribution** of the random variable.  \n",
    "\n",
    "Example:  \n",
    "Suppose a random variable $X$, which takes {1,2,3,4}, when recorded at every hour, we get ~  \n",
    "{4,3,4,3,2,4,1,3,2,2,1,3,1,2,3,4}  \n",
    "**Weighted Average**(Expectation) = $\\frac{\\sum_x  x\\space{1mm}\\times\\space{1mm}frequency_x }{total frequency}$ = $\\frac{(1x3)+(2x4)+(3x5)+(4x4)}{16}$,  \n",
    "  which can also be written as = $1x\\frac{3}{16}\\space{1mm}+\\space{1mm}2x\\frac{2}{16}+3x\\frac{3}{16}+4x\\frac{4}{16}$  \n",
    "  or, $\\hspace{4cm}$= $\\sum_i x_i~\\times~P(X=x_i)$  \n",
    "  \n",
    "  \n",
    "Therefore, Formula for **Expectation**:  \n",
    "\n",
    "$\\hspace{3mm}E[X] = \\sum_i (x_i \\times f(x_i))\\hspace{3mm}$ (for discrete)  \n",
    "  \n",
    "$\\hspace{1.5cm}= \\int_{-\\infty}^{\\infty} (x \\times f(x))\\hspace{1mm}dx\\hspace{3mm}$ (for continuous)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3a890d",
   "metadata": {},
   "source": [
    "For a Random Variable expectation may or may not exist.  \n",
    "A random variable X has a finite Expectation ( or E[X] exists ), If \n",
    "  * $\\sum_x |x| \\times f(x)<\\infty$\n",
    "  * $\\int_{-\\infty}^{\\infty} |x| \\times f(x)\\hspace{1mm}dx < \\infty$\n",
    "  \n",
    "** Example for r.v X=1,2,3,... having pdf $f(x) = \\frac{1}{x(x+1)}$, **expectation does not exist**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafb5886",
   "metadata": {},
   "source": [
    "### Properties of Expectation   \n",
    "* $E[g(X)] = \\sum_x g(x) f(x) \\hspace{2mm}or\\hspace{2mm} \\int_{-\\infty}^{\\infty} g(x)f(x)~dx$\n",
    "  \n",
    "  \n",
    "* $E[k] = k~~$(k : constant)\n",
    "* $E[kX] = kE[X]~~$(X : r.v)  \n",
    "* $E[aX+b] = aE[X] +b$\n",
    "* $E[E[X]] = E[X]~~$\n",
    "* $E[X_1 +....+ X_n] = E[X_1] +....+E[X_n]$  \n",
    "  \n",
    "  (X,Y : r.v)  \n",
    "* $E[g(X,Y)] = \\sum_x \\sum_y g(x,y)  f_{XY}(x,y)\\hspace{2mm}or\\hspace{2mm}\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} g(x,y)f(x)~dx$    \n",
    "  \n",
    "  \n",
    "* $E[X+Y] = E[X] + E[Y]\\hspace{2mm}$  \n",
    "* $E[XY] = E[X] E[Y]$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c3e97",
   "metadata": {},
   "source": [
    "### Moments of Random Variable  \n",
    "The “moments” of a random variable (or of its distribution) are expected values of powers of the random variable.  \n",
    "So, $r^{th}$ moment of r.v $X$ is:  \n",
    "$\\hspace{3mm}E[X^r] = \\sum_x x^r \\times f(x) \\hspace{1mm}or\\hspace{1mm} \\int_{-\\infty}^{\\infty} x^r \\times f(x)~dx$  \n",
    "\n",
    "### Moment Generating Function  \n",
    "$\\varphi_X (t) = E[e^{tX}] = \\sum_x e^{tx}f(x) \\hspace{3mm}or\\hspace{3mm} \\int_{-\\infty}^{\\infty} e^{tx} f(x)~dx$  \n",
    "  \n",
    "* first moment $E[X] = \\frac{d}{dx} \\varphi_X(0)\\hspace{1mm}$(first derivative of m.g.f at **t=0**)  \n",
    "* second moment $E[X^2] = \\frac{d^2}{dx^2} \\varphi_X(0)\\hspace{1mm}$(second derivative of m.g.f at **t=0**)  \n",
    ".    \n",
    ".  \n",
    ".  \n",
    "* rth moment $E[X] = \\frac{d^r}{dx^r} \\varphi_X(0)\\hspace{1mm}$(rth derivative of m.g.f at **t=0**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35189b15",
   "metadata": {},
   "source": [
    "### Variance\n",
    "Variance is a measure of dispersion, meaning it is a measure of how far a set of numbers is spread out from their average value.  \n",
    "From the last example, X was recorded ~ {4,3,4,3,2,4,1,3,2,2,1,3,1,2,3,4}  \n",
    "Mean($\\mu)\\hspace{1mm}=\\hspace{1mm}E[X]$ = 2.625  \n",
    "**Variance** = $\\frac{\\sum_x   (x-E[X])^2 \\hspace{1mm}\\times\\hspace{1mm}frequency_x}{total frequency} = \\frac{(1-2.625)^2x3\\hspace{1mm}+\\hspace{1mm}(2-2.625)^2x4\\hspace{1mm}+\\hspace{1mm}(3-2.625)^2x5\\hspace{1mm}+\\hspace{1mm}(4-2.625)^2x4}{16}$  \n",
    "  \n",
    "$\\hspace{1.8cm}= \\sum_x (x-\\mu)^2 \\times f(x) \\hspace{2mm}or\\hspace{2mm} \\int_{-\\infty}^{\\infty} (x-\\mu)^2 \\times f(x)~dx$ \n",
    "  \n",
    "therefore we can write,      \n",
    "$Var[X] = E[(X-E[X])^2]$  \n",
    "or, $\\hspace{1cm}=E[X^2 + (E[X])^2 - 2XE[X] ]$  \n",
    "or, $\\hspace{1cm} =E[X^2] + E[E[X]^2] - E[2XE[X]]$   \n",
    "or, $\\hspace{1cm} = E[X^2] + E[X]^2 - 2E[X]E[E[X]]$  \n",
    "or, $\\hspace{1cm} = E[X^2] + E[X]^2 - 2E[X]E[X]$  \n",
    "  \n",
    "  \n",
    "or, $Var[X]~= E[X^2] - E[X]^2$  \n",
    "$\\hspace{1.8cm}= \\frac{d^2}{dx^2} \\varphi_X(0) -(\\frac{d}{dx} \\varphi_X(0))^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a050b9e",
   "metadata": {},
   "source": [
    "### Central Moment  \n",
    "A **central moment** is a **moment** of a probability distribution of a random variable about the random variable's **mean**.   \n",
    "\n",
    "So, $m^{th}$ Central moment of r.v. $X$ having mean $\\mu$, can be written as:  \n",
    "$\\hspace{2mm}E[(X-\\mu)^m] =  \\sum_x (x-\\mu)^m \\times f(x) \\hspace{2mm}or\\hspace{2mm} \\int_{-\\infty}^{\\infty} (x-\\mu)^m \\times f(x)\\hspace{1mm}dx$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79cfae2",
   "metadata": {},
   "source": [
    "### Conditional Expectation  \n",
    "Let $X$ and $Y$ be 2 Random Variables.  \n",
    "Joint Density Function of $X$ and $Y$ be $f(x,y)$.\n",
    "Where, $f_X(x)$ and $F_Y(y)$ are the marginal desity functions.  \n",
    "  \n",
    "Then **Conditional Expectation** of $X$ given $Y$ is   \n",
    "$E[X|Y=y] = \\int_{-\\infty}^{\\infty} x\\cdot f_{X|Y}(x|Y=y) dx$  \n",
    "Where,  \n",
    "$f_{X|Y}(x|Y=y) = \\frac{f(x,y)}{f_Y(y)}$ is the **conditional probability function** of $X$ given $Y$, if $f_Y(y) \\neq 0$.  \n",
    "  \n",
    "Therefore,  \n",
    "$E[X|Y=y] = \\frac{1}{f_Y(y)} \\int_{-\\infty}^{\\infty} x\\cdot f(x,y)\\hspace{1mm} dx,\\hspace{4mm}$ if $f_Y(y) \\neq 0$.  \n",
    "  \n",
    "    \n",
    "Similarly,  \n",
    "**Conditional Expectation** of $Y$ given $X$ is  \n",
    "$E[Y|X=x] = \\frac{1}{f_X(x)} \\int_{-\\infty}^{\\infty} y\\cdot f(x,y)\\hspace{1mm} dx,\\hspace{4mm}$ if $f_X(x) \\neq 0$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
